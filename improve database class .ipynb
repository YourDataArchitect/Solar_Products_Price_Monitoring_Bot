{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "os.chdir('D:\\scrapy_projects\\current projects\\scrapy_projects\\simon\\output')\n",
    "list_all_files = os.listdir()\n",
    "\n",
    "list_results = []\n",
    "for file_name in list_all_files:\n",
    "    dict_file_names = {}\n",
    "    dict_file_names['name'] = file_name\n",
    "    dict_file_names['count_inside_files'] = len(os.listdir(file_name))\n",
    "    list_results.append(dict_file_names)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coversyl Arginin (Perindopril Arginin)\n",
      "2\n",
      "Dermovate Salbe\n",
      "1\n",
      "Dymista Nasenspray\n",
      "1\n",
      "Elocon Kopfhautlotion (MometasonFuroat)\n",
      "2\n",
      "Epiduo Gel (Adapalen _ Benzoylperoxid)\n",
      "1\n",
      "Incruse Ellipta (Umeclidinium)\n",
      "2\n",
      "Jentadueto (Linagliptin _ Metformin-hydrochlorid)\n",
      "2\n",
      "Mounjaro (Tirzepatid)\n",
      "1\n",
      "NuvaRing (Etonogestrel _ Ethinylestradiol)\n",
      "1\n",
      "Ozempic (Semaglutid)\n",
      "2\n",
      "PrEP (Emtricitabine_Tenofovir)\n",
      "2\n",
      "Rabeprazol\n",
      "1\n",
      "Serevent Evohaler (Salmeterol)\n",
      "2\n",
      "Wartec\n",
      "1\n",
      "WegovyÂ® (Semaglutid)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for element in list_results:\n",
    "    if element['count_inside_files'] < 3:\n",
    "        print(element['name']) \n",
    "        print(f'{element[\"count_inside_files\"]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "237"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "products_from_files = pd.read_csv(r\"D:\\scrapy_projects\\current projects\\scrapy_projects\\simon\\all_products.csv\")\n",
    "\n",
    "list_names_products = products_from_files['name'].tolist()\n",
    "for name in li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sheetsgoogle'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import os \n",
    "\n",
    "current_dirct = os.getcwd()\n",
    "\n",
    "df = pd.read_excel(current_dirct+\"\\KEYS.xlsx\" , index_col='key')\n",
    "user = df.at['user','value']\n",
    "host = df.at['host','value']\n",
    "password = df.at['password','value']\n",
    "database = df.at['database','value']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from tabulate import tabulate\n",
    "import logging\n",
    "import concurrent.futures\n",
    "import time\n",
    "from googleapiclient.errors import HttpError\n",
    "from httplib2 import ServerNotFoundError\n",
    "from requests.exceptions import Timeout, ConnectionError\n",
    "import smtplib\n",
    "from mysql.connector import errors\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "import time \n",
    "import subprocess\n",
    "import os \n",
    "import undetected_chromedriver as uc\n",
    "import locale\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import gspread\n",
    "import pytz\n",
    "from scrapy.crawler import CrawlerRunner\n",
    "from twisted.internet import reactor, defer\n",
    "from google.oauth2 import service_account\n",
    "import os \n",
    "import time\n",
    "from datetime import datetime,timedelta\n",
    "import pandas as pd \n",
    "from googleapiclient.discovery import build\n",
    "import scrapy \n",
    "import socket\n",
    "import random \n",
    "import gzip\n",
    "import ssl\n",
    "import io\n",
    "from scrapy.exceptions import NotConfigured\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "import threading\n",
    "import pymysql\n",
    "\n",
    "warning_list = []\n",
    "\n",
    "class Tools : \n",
    "    def current_date_New_products_spider():\n",
    "        current_date = datetime.now()\n",
    "        formatted_date = current_date.strftime(\"%d_%m_%Y\")\n",
    "        return formatted_date\n",
    "\n",
    "def retry_decorator(func):\n",
    "    \"This function for handel target function with unstable connections\"\n",
    "    def wrapper(*args, **kwargs):\n",
    "        for i in range(70): # for wait 180 seconds (3 minutes)\n",
    "            try : \n",
    "                result = func(*args, **kwargs)\n",
    "                return result \n",
    "            except (HttpError,pymysql.MySQLError, ServerNotFoundError , ssl.SSLError,socket.error, TimeoutError , Timeout , ConnectionError , errors.InterfaceError , errors.DatabaseError) as e:\n",
    "                print(f\"Attempt {i} failed: {e}\")\n",
    "                time.sleep(5)\n",
    "        raise Exception(\"After 3 minutes, the retry attempt failed.\\nReason unstable connection .\")\n",
    "    return wrapper\n",
    "        \n",
    "\n",
    "class Database_Mangment:\n",
    "    def __init__(self):\n",
    "        # Define database config\n",
    "        current_dirct = os.getcwd()\n",
    "        file_path = os.path.join(current_dirct,'KEYS.xlsx')\n",
    "        df = pd.read_excel(file_path , index_col='key')\n",
    "        \n",
    "        try : \n",
    "            self.connection = mysql.connector.connect(\n",
    "                host= df.at['host','value'],\n",
    "                user= df.at['user','value'],\n",
    "                password= df.at['password','value'],\n",
    "                database=df.at['database','value'])\n",
    "            \n",
    "            print('-- >> Database Connection established Successfully !!! ')\n",
    "            \n",
    "            # Create a cursor object to interact with the database\n",
    "            self.cursor = self.connection.cursor()\n",
    "            \n",
    "        except Error as e : \n",
    "            warning_list.append(f'Opening Connection Database error: {e} - line 271')\n",
    "            print(f'Opening Connection Database error: {e}')\n",
    "        \n",
    "    @retry_decorator\n",
    "    def Add_unvalid_url_to_Database_New_products(self,url,source):\n",
    "        print('-- >> Adding Unvalid LINKS to database')\n",
    "        # Establish a connection to the MySQL server\n",
    "        # Iterate through the list of dictionaries and insert each record\n",
    "        new_dict_for_upload = {}\n",
    "        new_dict_for_upload['SOURCE'] = source\n",
    "        new_dict_for_upload['URL'] = url\n",
    "        new_dict_for_upload['Update_date'] = Tools.current_date_New_products_spider()\n",
    "        keys_string = ', '.join(new_dict_for_upload.keys())\n",
    "        values_placeholder = ', '.join(['%s'] * len(new_dict_for_upload))\n",
    "        values_tuple = tuple(new_dict_for_upload.values())\n",
    "\n",
    "        insert_query = f'''INSERT INTO sheetsgoogle.New_Products ({keys_string}) VALUES ({values_placeholder})'''\n",
    "        \n",
    "        print(f'Insert Record to \"New_products\" table: {values_tuple}')\n",
    "        \n",
    "        self.cursor.execute(insert_query, values_tuple)\n",
    "\n",
    "        # # # # # Commit the changes to the database\n",
    "        self.connection.commit()\n",
    "\n",
    "    @retry_decorator\n",
    "    def Extract_last_5_prices_from_database(self,URL) -> list[dict]:\n",
    "        '''This Functuion for get records from the database using the given URL'''\n",
    "        # get data from database and the output is list of rows\n",
    "        self.cursor.execute(f'''\n",
    "                        SELECT * FROM `Follow_Up_Competitors_Prices`\n",
    "                        WHERE URL = '{URL}';''')\n",
    "        result_all_data = self.cursor.fetchall()\n",
    "        self.cursor.execute(f\"SHOW COLUMNS FROM `Follow_Up_Competitors_Prices`;\")\n",
    "        columns = self.cursor.fetchall()\n",
    "        columns\n",
    "        columns_names = tuple([record[0] for record in columns])\n",
    "        columns_names\n",
    "        result_all_data.append(columns_names)\n",
    "        result_all_data\n",
    "        list_dicts_records = pd.DataFrame(result_all_data , columns= result_all_data[-1]).to_dict(orient='records')[0]\n",
    "        list_dicts_records\n",
    "        if list_dicts_records['Source'] != 'Source':\n",
    "            columns_list = ['Price_1_day_ago','Price_2_day_ago','Price_3_day_ago','Price_4_day_ago','Price_5_day_ago']\n",
    "            for column in columns_list:\n",
    "                if list_dicts_records[column] == None : list_dicts_records[column] = '-'\n",
    "            \n",
    "            result = list_dicts_records['Price_1_day_ago'].strip()+', '+list_dicts_records['Price_2_day_ago'].strip()+', '+list_dicts_records['Price_3_day_ago'].strip()+', '+list_dicts_records['Price_4_day_ago'].strip()+', '+list_dicts_records['Price_5_day_ago'].strip()\n",
    "            result = result.replace('\\xa0',' ').replace(' â¬','')\n",
    "            return result\n",
    "        else:\n",
    "            return '-'\n",
    "        \n",
    "    @retry_decorator\n",
    "    def read_records_NEW_PRODUCTS_database_New_products_spider(self) -> list[dict]:\n",
    "        '''This Functuion for get records from the database '''\n",
    "        tableName = 'New_Products'\n",
    "        self.cursor.execute(f\"SELECT URL FROM {tableName}\")\n",
    "        result_all_data = self.cursor.fetchall()\n",
    "        set_records = {url[0] for url in result_all_data}\n",
    "        return set_records\n",
    "\n",
    "    @retry_decorator\n",
    "    def Add_Records_to_Database_New_products_spider(self,LIST_OF_dicts):\n",
    "        # INPUT LIST CONTAINS URL'S \n",
    "        # Example : input = ['URL_1', 'URL_2', 'URL_3', 'URL_4']\n",
    "        \n",
    "        print('-- >> Adding NEW PRODUCTS LINKS to database')\n",
    "\n",
    "        # Iterate through the list of dictionaries and insert each record\n",
    "        for record in LIST_OF_dicts:\n",
    "            # print(record)\n",
    "            new_dict_for_upload = {}\n",
    "            new_dict_for_upload['SOURCE'] = record['Source']\n",
    "            new_dict_for_upload['URL'] = record['URL']\n",
    "            new_dict_for_upload['Update_date'] = Tools.current_date_New_products_spider()\n",
    "            keys_string = ', '.join(new_dict_for_upload.keys())\n",
    "            values_placeholder = ', '.join(['%s'] * len(new_dict_for_upload))\n",
    "            values_tuple = tuple(new_dict_for_upload.values())\n",
    "\n",
    "            insert_query = f'''INSERT INTO sheetsgoogle.New_Products ({keys_string}) VALUES ({values_placeholder})'''\n",
    "            \n",
    "            print(f'Insert Record to \"New_products\" table: {values_tuple}')\n",
    "            self.cursor.execute(insert_query, values_tuple)\n",
    "\n",
    "        # # # # # Commit the changes to the database\n",
    "        self.connection.commit()\n",
    "\n",
    "        \n",
    "    @retry_decorator\n",
    "    def check_connection(self):\n",
    "        try:\n",
    "            if self.connection.is_connected():\n",
    "                print(\"Successfully connected to the database\")\n",
    "                \n",
    "                # Print the MariaDB server version\n",
    "                db_info = self.connection.get_server_info()\n",
    "                print(f\"MariaDB server version: {db_info}\")\n",
    "                \n",
    "                # Create a cursor object\n",
    "                cursor = self.connection.cursor()\n",
    "                \n",
    "                # Execute a simple query\n",
    "                cursor.execute(\"SELECT DATABASE();\")\n",
    "                record = cursor.fetchone()\n",
    "                print(f\"You're connected to database: {record}\")\n",
    "            \n",
    "\n",
    "        \n",
    "        except Error as e:\n",
    "            warning_list.append(f'Error while connecting to MariaDB: {e} - line 207')\n",
    "            print(f\"Error while connecting to MariaDB: {e}\")\n",
    "\n",
    "    @retry_decorator\n",
    "    def read_records_database(self,tableName) -> list[dict]:\n",
    "        '''This Functuion for get records from the database '''\n",
    "        # get data from database and the output is list of rows\n",
    "        self.cursor.execute(f\"SELECT * FROM {tableName}\")\n",
    "        result_all_data = self.cursor.fetchall()\n",
    "        self.cursor.execute(f\"SHOW COLUMNS FROM {tableName};\")\n",
    "        columns = self.cursor.fetchall()\n",
    "        columns_names = tuple([record[0] for record in columns])\n",
    "        result_all_data.append(columns_names)\n",
    "        list_dicts_records = pd.DataFrame(result_all_data , columns= result_all_data[-1]).to_dict(orient='records')\n",
    "        return list_dicts_records\n",
    "            \n",
    "    @retry_decorator\n",
    "    def Add_Records_to_Database_Follow_Up_Competitors_Prices(self,record,connection,cursor):\n",
    "        try : \n",
    "            # Get keys string\n",
    "            keys_list = [key for key in record]\n",
    "            keys_list_after_replace = list(map(lambda x: x.replace('.', '_').replace('Preise','Price') if '2024' or '2025' in x else x , keys_list))\n",
    "            keys_list_after_replace\n",
    "\n",
    "            keys_string = ','.join(keys_list_after_replace)\n",
    "            values_string = ', '.join(['%s'] * len(keys_list))\n",
    "\n",
    "            # SQL query to insert data into a table\n",
    "            insert_query = f'''INSERT INTO Follow_Up_Competitors_Prices ({keys_string}) VALUES ({values_string})'''\n",
    "            \n",
    "            # Create tuple of values\n",
    "            data_tuple = tuple(record.values())\n",
    "            data_tuple\n",
    "            # If any value is a string, replace '.' with '_'\n",
    "\n",
    "            # Execute the query\n",
    "            cursor.execute(insert_query, data_tuple)\n",
    "            \n",
    "            # Commit the changes to the database\n",
    "            connection.commit()\n",
    "            \n",
    "            \n",
    "        except mysql.connector.Error as err:\n",
    "            warning_list.append(f'MySQL Error: {err} - line 300')\n",
    "            print(f\"Error: {err}\")\n",
    "        except Exception as e:\n",
    "            warning_list.append(f'MySQL Error: {err} - line 303')\n",
    "            print(f\"Exception: {e}\")\n",
    "            \n",
    "\n",
    "    @retry_decorator\n",
    "    def extract_record_from_database_using_url(self,tableName,URL) -> list[dict]:\n",
    "        '''This Functuion for get records from the database using the given URL'''\n",
    "        self.cursor.execute(f'''\n",
    "                        SELECT * FROM `{tableName}`\n",
    "                        WHERE URL = '{URL}';''')\n",
    "        result_all_data = self.cursor.fetchall()\n",
    "        self.cursor.execute(f\"SHOW COLUMNS FROM {tableName};\")\n",
    "        columns = self.cursor.fetchall()\n",
    "        columns_names = tuple([record[0] for record in columns])\n",
    "        result_all_data.append(columns_names)\n",
    "        list_dicts_records = pd.DataFrame(result_all_data , columns= result_all_data[-1]).to_dict(orient='records')[0]\n",
    "        \n",
    "        # Testing is record is exist in Database or not exist in Database\n",
    "        if list_dicts_records['Source'] != 'Source':\n",
    "            return list_dicts_records\n",
    "        else:\n",
    "            raise ValueError('Error_Record_not_exist')\n",
    "\n",
    "    @retry_decorator\n",
    "    def delete_record_from_database(self,record_url):\n",
    "        '''This Functuion for Delete all old records according to URL OF RECORD '''\n",
    "        try :\n",
    "            self.cursor.execute(f'''\n",
    "                        DELETE FROM sheetsgoogle.Follow_Up_Competitors_Prices\n",
    "                        WHERE URL = '{record_url}';''')\n",
    "            self.connection.commit()\n",
    "            # print(f'Record Deleted succefully URL : {record_url}')\n",
    "        except Error as e:\n",
    "            warning_list.append(f'Error for delete records: {e} - Line 361')\n",
    "            print(f'Error for delete records : {e}')\n",
    "            \n",
    "    @retry_decorator\n",
    "    def update_column_database(self) -> str :\n",
    "        '''\n",
    "        This Functuion for add missing column headers  \n",
    "        Return : string for current date \n",
    "        '''\n",
    "        self.cursor.execute(f\"SHOW COLUMNS FROM sheetsgoogle.Follow_Up_Competitors_Prices;\")\n",
    "        columns = self.cursor.fetchall()\n",
    "        columns_names_from_database = tuple([record[0] for record in columns])\n",
    "        new_column_date = Tools.current_date().replace('.','_')\n",
    "        # check if there all column in record are present in database and if not present create new column\n",
    "        if new_column_date in columns_names_from_database : \n",
    "            pass \n",
    "        else : \n",
    "            self.cursor.execute(f'''ALTER TABLE `sheetsgoogle`.`Follow_Up_Competitors_Prices` ADD COLUMN `{new_column_date}` Text NULL AFTER `Price_5_day_ago`;''')\n",
    "\n",
    "    def __del__(self):\n",
    "        # Close the cursor and connection\n",
    "        if self.cursor:\n",
    "            self.cursor.close()\n",
    "        if self.connection:\n",
    "            self.connection.close()\n",
    "        \n",
    "        print(\"MySQL connection is closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- >> Database Connection established Successfully !!! \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Source': 'Tom_Cars_Hi_Fi',\n",
       " 'URL': 'https://www.toms-car-hifi.de/technikwelt/freizeit/solar/zubehoer/53950/syn-100-xh-30-mid-xh?number=74125',\n",
       " 'Name_shop': None,\n",
       " 'Product_name': 'Growatt - SYN-100-XH-30 (MID XH)',\n",
       " 'Price': '569,11 â¬',\n",
       " 'available': 'Ja',\n",
       " 'Price_1_day_ago': '569,90 â¬',\n",
       " 'Price_2_day_ago': '569,90 â¬',\n",
       " 'Price_3_day_ago': '569,90 â¬',\n",
       " 'Price_4_day_ago': '569,90 â¬',\n",
       " 'Price_5_day_ago': '569,90 â¬',\n",
       " '22_09_2024': '569,90 â¬',\n",
       " '21_09_2024': '569,90 â¬',\n",
       " '20_09_2024': '569,90 â¬',\n",
       " '19_09_2024': '569,90 â¬',\n",
       " '18_09_2024': '569,90 â¬',\n",
       " '17_09_2024': '569,90 â¬',\n",
       " '16_09_2024': '569,90 â¬',\n",
       " '15_09_2024': '569,90 â¬',\n",
       " '14_09_2024': '569,90 â¬',\n",
       " '13_09_2024': '569,90 â¬',\n",
       " '12_09_2024': '569,90 â¬',\n",
       " '11_09_2024': '569,90 â¬',\n",
       " '10_09_2024': '569,90 â¬',\n",
       " '09_09_2024': '569,90 â¬',\n",
       " '08_09_2024': '569,90 â¬',\n",
       " '07_09_2024': '569,90 â¬',\n",
       " '06_09_2024': '569,90 â¬',\n",
       " '05_09_2024': '569,90 â¬',\n",
       " '04_09_2024': '569,90 â¬',\n",
       " '03_09_2024': '569,90 â¬',\n",
       " '02_09_2024': '569,90 â¬',\n",
       " '01_09_2024': '569,90 â¬',\n",
       " '31_08_2024': '569,90 â¬',\n",
       " '30_08_2024': '569,90 â¬',\n",
       " '29_08_2024': '569,90 â¬',\n",
       " '28_08_2024': '569,90 â¬',\n",
       " '27_08_2024': '569,90 â¬',\n",
       " '26_08_2024': '569,90 â¬',\n",
       " '25_08_2024': '569,90 â¬',\n",
       " '24_08_2024': '569,90 â¬',\n",
       " '23_08_2024': '569,90 â¬',\n",
       " '22_08_2024': '569,90 â¬',\n",
       " '21_08_2024': '569,90 â¬',\n",
       " '20_08_2024': '569,90 â¬',\n",
       " '19_08_2024': '569,90 â¬',\n",
       " '18_08_2024': '569,90 â¬',\n",
       " '17_08_2024': '569,90 â¬',\n",
       " '16_08_2024': '569,90 â¬',\n",
       " '15_08_2024': '569,90 â¬',\n",
       " '14_08_2024': '569,90 â¬',\n",
       " '13_08_2024': '569,90 â¬',\n",
       " '12_08_2024': None,\n",
       " '11_08_2024': None,\n",
       " '10_08_2024': '569,11 â¬',\n",
       " '09_08_2024': '569,11 â¬',\n",
       " '08_08_2024': '569,11 â¬',\n",
       " '07_08_2024': '569,11 â¬',\n",
       " '06_08_2024': '569,11 â¬',\n",
       " '05_08_2024': None,\n",
       " '04_08_2024': '569,11 â¬',\n",
       " '03_08_2024': '569,11 â¬',\n",
       " '02_08_2024': '569,11 â¬',\n",
       " '01_08_2024': '569,11 â¬',\n",
       " '31_07_2024': '569,11 â¬',\n",
       " '30_07_2024': None,\n",
       " '29_07_2024': '569,11 â¬',\n",
       " '28_07_2024': '569,11 â¬',\n",
       " '27_07_2024': '569,11 â¬',\n",
       " '25_07_2024': None,\n",
       " '24_07_2024': None,\n",
       " 'Date': '22_09_2024'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database = Database_Mangment()\n",
    "\n",
    "database.extract_record_from_database_using_url('Follow_Up_Competitors_Prices','https://www.toms-car-hifi.de/technikwelt/freizeit/solar/zubehoer/53950/syn-100-xh-30-mid-xh?number=74125')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
